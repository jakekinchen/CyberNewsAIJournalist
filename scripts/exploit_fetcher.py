from supabase_utils import supabase
from extract_text import scrape_content

starting_edb_id = 51667
url_base = "https://www.exploit-db.com/exploits/"

def determine_latest_exploit():
    # Get the latest exploit
    print("Determining latest exploit")
    response = supabase.table("exploits").select("*").order("edb_id").limit(1).execute()
    latest_exploit = response.data[0] if response.data else None
    return latest_exploit

def determine_oldest_exploit():
    # Get the oldest exploit
    print("Determining oldest exploit")
    response = supabase.table("exploits").select("*").order("edb_id" ).limit(1).execute()
    oldest_exploit = response.data[0] if response.data else None
    return oldest_exploit

def get_list_of_exploits():
    # Get a list of all exploits
    response = supabase.table("exploits").select("*").execute()
    exploits = response.data
    return exploits

def upload_exploit(content):
    # Upload the exploit title, code, edb_id, author, type, platform, date, and content to Supabase. Each of these values are stored in a json structured object named content
    try:
        response = supabase.table("exploits").insert([content]).execute()
        print(f"Successfully uploaded exploit with EDB-ID {content['edb_id']}")
    except Exception as error:
        print(f"Failed to upload exploit: {error}")

async def fetch_latest_exploits():
    # Fetch the latest exploits from Exploit-DB
    print("Fetching latest exploits")
    latest_exploit = determine_latest_exploit()
    edbid = latest_exploit['edb_id'] if latest_exploit else starting_edb_id
    while True:
        url = f"{url_base}{edbid}"
        try: 
            content, links = await scrape_content(url)
            #print(f"Successfully fetched exploit from {url}")
        except Exception as error:
            print(f"Failed to scrape exploit from {url}: {error}")
            break
        if content:
            #print(f"Successfully scraped source from {url}")
            print(content)
            upload_exploit(content)
        else:
            print(f"Failed to scrape source from {url}")
        edbid += 1
            
async def fetch_past_exploits(quantity):
    # Fetch a specified quantity of exploits from Exploit-DB
    print(f"Fetching {quantity} past exploits")
    if quantity < 1:
        print("Quantity must be greater than 0")
        return
    oldest = determine_oldest_exploit()
    edbid = oldest['edb_id'] if oldest else starting_edb_id
    while quantity > 0:
        url = f"{url_base}{edbid}"
        try: 
            content, links = await scrape_content(url)
        except Exception as error:
            print(f"Failed to scrape exploit from {url}: {error}")
            break
        if content:
            #print(f"Successfully scraped source from {url}")
            upload_exploit(content)
        else:
            print(f"Failed to scrape source from {url}")
        edbid -= 1
        quantity -= 1